{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Psi' = \\alpha \\Psi $$\n",
    "\n",
    "Solution:\n",
    "\n",
    "$$\\Psi(t) = e^{\\alpha t}$$\n",
    "\n",
    "Integral form:\n",
    "\n",
    "$$\\Psi(t) = \\int_0^t \\alpha \\Psi(s) \\,ds + 1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.4\n",
    "\n",
    "N = nn.Sequential(nn.Linear(1, 15), nn.Sigmoid(), nn.Linear(15,1, bias=False))\n",
    "\n",
    "Psi_t = lambda x: 1+x*N(x)\n",
    "f_integrand = lambda x, Psi: alpha*Psi\n",
    "psi_0 = 1\n",
    "\n",
    "Psi_real = lambda x: torch.exp(alpha*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Grid\n",
    "n_points = 10\n",
    "x_train = np.linspace(0, 2, n_points)[:, None]       # Train from 0 to 2\n",
    "x = torch.Tensor(x_train)\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Approximation of integrals\n",
    "def Trapez(t, n_rectangles):\n",
    "    ''' Returns the integral between 0 and t, by dividing into n intervals'''\n",
    "    x_in_the_integral = np.linspace(0, t, n_rectangles)[:, None]\n",
    "    x_in_the_integral = torch.Tensor(x_in_the_integral)\n",
    "    \n",
    "    y = Psi_t(x_in_the_integral)\n",
    "    integrand = f_integrand(x_in_the_integral, y)\n",
    "    integral = torch.trapezoid(integrand[:,0], x_in_the_integral[:,0])\n",
    "    \n",
    "    return integral\n",
    "\n",
    "def Rectangles(t, n_rectangles):\n",
    "    \n",
    "    x_in_the_integral = np.linspace(0, t, n_rectangles)[:, None]\n",
    "    x_in_the_integral = torch.Tensor(x_in_the_integral)\n",
    "    y = Psi_t(x_in_the_integral)\n",
    "    integrand = f_integrand(x_in_the_integral, y)\n",
    "\n",
    "    delta_x = t/(n_rectangles-1) \n",
    "\n",
    "    heights_left_rectangles = integrand[:,0][0:-1]  # We are taking all components except for the last\n",
    "    integral = torch.sum(heights_left_rectangles)*delta_x\n",
    "    \n",
    "    return integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-modify-the-gradient-manually/7483/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1814, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = 0.5\n",
    "n_rectangles = 22\n",
    "Rectangles(time,n_rectangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1805, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trapez(time,n_rectangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_int = 10\n",
    "\n",
    "def loss(x):\n",
    "    \n",
    "    outputs = Psi_t(x) \n",
    "    integrals_vector = torch.tensor([[Rectangles(i, n_int) for i in x[:,0].tolist()]]) + 1\n",
    "    \n",
    "    final_loss = torch.mean( (outputs - integrals_vector)  ** 2)\n",
    "    \n",
    "    print('loss is', final_loss)\n",
    "\n",
    "    return  final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(N.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    l = loss(x)\n",
    "    l.backward()\n",
    "    # for p in N.parameters():\n",
    "    #    print(\"parameters are:\", p)\n",
    "    #    p.grad  # Access the gradients\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.5176, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.5082, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4989, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4898, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4808, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4720, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4633, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4547, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4464, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4381, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4300, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4220, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4142, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.4066, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3991, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3917, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3845, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3774, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3705, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3637, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3571, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3506, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3443, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3381, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3320, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3261, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3203, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3147, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3092, grad_fn=<MeanBackward0>)\n",
      "loss is tensor(0.3039, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa942490978>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhdVb3/8fc389gMTec2bZks8xSBIoVCVSiCCHqRUUG4dQBEQUXxXriKvyteBcULiBV6a69cqkCBgqDMc1tooQMtUDrRmWZqxmZevz/WTnqaJu1Je052cvJ5PU+enLP3Ptnf7px+zs7aa61tzjlERKT/Swq7ABERiQ0FuohIglCgi4gkCAW6iEiCUKCLiCSIlLB2XFRU5MaNGxfW7kVE+qVFixaVOeeGdLUutEAfN24cCxcuDGv3IiL9kpl93N06NbmIiCQIBbqISIJQoIuIJAgFuohIglCgi4gkCAW6iEiCUKCLiCQIBbqISG9pa4NXfg1blsTlx4c2sEhEZECpK4M5/wqrX4TmOhhxdMx3sdczdDMbY2YvmdkKM1tuZtd3sc2lZrbUzJaZ2ZtmFvtKRUT6q/UL4L5JsO4NOOd3MOXWuOwmmjP0FuBG59w7ZpYLLDKz55xzKyK2WQuc5pyrNLOpwHTgxDjUKyLSfzgH8+6B52+FvNFw1bMw8pi47W6vge6c2wJsCR7XmNn7wChgRcQ2b0a8ZD4wOsZ1ioj0Lzu2wxPXwAdPwYRz4Lx7IDM/rrvsURu6mY0DjgUW7GGzq4Bnunn9NGAaQHFxcU92LSLSf2xZAn/7GmzfAJ//fzDxGjCL+26jDnQzywEeBb7nnKvuZpvT8YF+SlfrnXPT8c0xlJSU6O7UIpJYnINFM+GZmyBrMFz5NBSf1Gu7jyrQzSwVH+YPOufmdLPNUcD9wFTnXHnsShQR6Qea6uCpG2DpbDjgdPjy/ZBd1Ksl7DXQzcyAB4D3nXN3drNNMTAHuNw5tzK2JYqI9HGlK30TS+kHMPkncOoPISm518uI5gz9M8DlwDIzWxwsuxkoBnDO3QfcAgwG7vX5T4tzriT25YqI9DHLHoG534XUDLh8Dhx4RmilRNPL5XVgj635zrmrgatjVZSISJ/X0gj/+AksfADGnAT/8j8waGSoJWmkqIhIT1Wug4evgM3vwsnX+YFCyalhV6VAFxHpkQ+fgce+CQ746oNw6DlhV9RBgS4iEo3WFnjx5/DGXTD8KLhwFhSOD7uqXSjQRUT2pnoLPPINWP8mHH8lnHW7vwjaxyjQRUT2ZM3L8OjVvp/5BX+Coy4Mu6JuKdBFRLrS1gav/QZe+k8oOgS+/hQMnRB2VXukQBcR6ayuPJi7/AU48kI457eQnhN2VXulQBcRibThLd8lsa7UB/nxV/bKxFqxoEAXEQE/sdb8e+G5W2DQKLjqubjOXR4PCnQRkYYqP3f5+0/22tzl8aBAF5GBbctSePjrUPkxfP4XMPHaftPE0pkCXUQGJufgnVnw9A9Dmbs8HhToIjLwNNXB32+EJQ+FNnd5PCjQRWRg6SNzl8eDAl1EBo5lj8CT10NKeuhzl8eDAl1EEl9TPTz7U1g4o8/MXR4PCnQRSWybFsGcaVC+Ck7+Lky5pU/MXR4PCnQRSUytLfDaHfDKryB3BHxtLhxwWthVxVXS3jYwszFm9pKZrTCz5WZ2fRfbmJn93sxWmdlSMzsuPuWKiEShfDXMOBNe/k844svw7TcSPswhujP0FuBG59w7ZpYLLDKz55xzKyK2mQocHHydCPwh+C4i0nucg0Uz4Z83+2aVr8zwgT5ARHOT6C3AluBxjZm9D4wCIgP9PGCWc84B880s38xGBK8VEYm/2m0w9zpY+Q84YDJ86Q8JeeFzT3rUhm5m44BjgQWdVo0CNkQ83xgs2yXQzWwaMA2guLi4Z5WKiHTng7/7MG+qg7N+BSdMg6S9tignnKj/xWaWAzwKfM85V70vO3POTXfOlTjnSoYMGbIvP0JEZKfGGnjiWph9iZ8hcdorcNK3BmSYQ5Rn6GaWig/zB51zc7rYZBMwJuL56GCZiEh8rF8Aj02D7evhlBv8qM+UtLCrClU0vVwMeAB43zl3ZzebzQW+FvR2OQmoUvu5iMRFSxO88HP4n7P8RdArnobP3jrgwxyiO0P/DHA5sMzMFgfLbgaKAZxz9wFPA2cDq4B64MrYlyoiA17ph/7WcFuWwLGXwZm/hIxBYVfVZ0TTy+V1YI+TAwe9W66JVVEiIrtoa4O3psPzt0JaNnz1L3DouWFX1edopKiI9G3Vm+Hx78Cal+DgM+GL/w25w8Kuqk9SoItI3/XeHHjq+9Da1O9u2BwGBbqI9D07tsMzP4Klf4VRx8P506HooLCr6vMU6CLSt6x9FR77NtRs8V0RJ/0AkhVV0dBREpG+obkBXrwN5t0DhQfAVc/B6OPDrqpfUaCLSPi2vufnLN+2HEqugs/f5nuzSI8o0EUkPG2tMO9uePEXkFkAlz4CB38u7Kr6LQW6iIRj+3rfVv7x6zDhHDj395A9OOyq+jUFuoj0LudgyWzfi8U5OO9eOOYSdUeMAQW6iPSe+gp46nuw4gkongjn3wcF48KuKmEo0EWkd6x6Hh6/BurLYcqt8JnrISk57KoSigJdROKrqd7PwfLWdBgyAS79G4w4OuyqEpICXUTiZ80r8OT1ULkWTvoOTLkFUjPDriphKdBFJPbqK+DZf4fFf4GC8fD1J2H8qWFXlfAU6CISO87B8jnwzE0+1E/5Ppx2k87Ke4kCXURiY/sG+PuN8NE/YeSxcNkcGHFU2FUNKAp0Edk/ba3w9v3+tnCuDc78Tzjhm5pQKwQ64iKy7z5ZAXOvg00L4cApcM6d6lceomhuEj3DzLaZ2XvdrM8zsyfNbImZLTcz3U9UJNE1N8ALt8EfJ/keLBf8CS57VGEesmjO0GcCdwOzull/DbDCOXeumQ0BPjSzB51zTTGqUUT6knVvwJPfhfJVcNRFvolFc7D0CdHcJPpVMxu3p02AXDMzIAeoAFpiUp2I9B07tvsBQotmQv5Yf9HzoClhVyURYtGGfjcwF9gM5AJfdc61dbWhmU0DpgEUFxfHYNci0itWzIWnfwh122DitXD6zZqvvA+KRaCfCSwGzgAOBJ4zs9ecc9WdN3TOTQemA5SUlLgY7FtE4ql6sw/yD56C4UfCJbN9l0Tpk2IR6FcCtzvnHLDKzNYCE4C3YvCzRSQMbW2waAY8/zNobYLP/gwmXgPJqWFXJnsQi0BfD0wBXjOzYcCngDUx+LkiEobSD2Hud2HDfBh/Gpz7O3+PT+nz9hroZvYQMBkoMrONwK1AKoBz7j7gNmCmmS0DDLjJOVcWt4pFJD5aGuH138Jrd0Bqlm480Q9F08vl4r2s3wx8PmYViUjvW7/ADxAq+xCO+AqcdTvkDAm7KukhjRQVGcgaquGFn8HbD0DeaLjkYThE52f9lQJdZKD64Gk/mVbNFjjxW3DGv0F6TthVyX5QoIsMNDVb/Q2aVzwBQw+Hr/4vjC4JuyqJAQW6yEDhHLwzy994oqUBzvh3f19PdUVMGAp0kYGgbJW/FdzHr8PYU+Dcu6DooLCrkhhToIskstZmeOMueOW/ICUDzv09HHs5JO11olXphxToIolq/Xx46gbYthwOOw+m/hfkDg+7KokjBbpIoqneDM/dCsv+BoNGwUUPwYSzw65KeoECXSRRNDfAvLvhtTuhrQUm/QAm3aBZEQcQBbpIf+ccfPgM/PMnULkOJpwDn/8FFI4PuzLpZQp0kf6s9EP4x49h9YswZAJc/jgceHrYVUlIFOgi/dGO7fDKr+Ct6ZCa7ede+fTV6lM+wCnQRfqTtjZY/Bc/T3l9ORz/dT9AKLso7MqkD1Cgi/QX6xf4IftbFsOYk+CyR2HkMWFXJX2IAl2kr4vshpg7Ei64H478iuYpl90o0EX6qpZG3w3x1Tt2dkM85fuaEVG6pUAX6Ws6uiHeDJVr1Q1RoqZAF+lLSlcG3RBfgKJPweWPwYFnhF2V9BPR3FN0BnAOsM05d0Q320wGfoe/12iZc+60WBYpkvAaqvwEWgvuUzdE2WfRnKHPBO4GZnW10szygXuBs5xz681saOzKE0lw7d0QX/g51JXBcV+DKbeoG6Lsk2huEv2qmY3bwyaXAHOcc+uD7bfFpjSRBLfhLd8NcfO7MOZEuPRhGHls2FVJPxaLNvRDgFQzexnIBe5yznV3Nj8NmAZQXFwcg12L9EPVW+D5/4ClsyF3hLohSszEItBTgOOBKUAmMM/M5jvnVnbe0Dk3HZgOUFJS4mKwb5H+o6UR5t0Dr/4G2pph0o1wyg3qhigxE4tA3wiUO+fqgDozexU4Gtgt0EUGJOdg5T/gHz/x3RA/9QU48xdQeEDYlUmCiUWgPwHcbWYpQBpwIvDbGPxckf6vdKWf1nbV874b4mVz4KApYVclCSqabosPAZOBIjPbCNyK756Ic+4+59z7ZvYPYCnQBtzvnHsvfiWL9AO7dEPMgjN/CSf8q7ohSlxF08vl4ii2+TXw65hUJNKftTbDopl+atu6MjjucjjjFsgZEnZlMgBopKhILLS1wfI58OIvfDv52M+oG6L0OgW6yP5wzg/Tf/5nsHUpDDsCLnkYDv6cuiFKr1Ogi+yrjQt9f/J1r0H+WLjgT3DEVyApKezKZIBSoIv0VOlKeOFn8MFTkD0Epv4ajr8CUtLCrkwGOAW6SLSqNsHLv4TFD/oJtCbfDBO/A+m5YVcmAijQRfauvgJevxMWTAccnPgtP8pTE2hJH6NAF+lOU53vR/76XdBYDUdfDJN/DAVjw65MpEsKdJHOWpvhnVm+L3ntJ3DIVD+l7bDDwq5MZI8U6CLt2tpgxWO+L3nFGiieCBfOguKTwq5MJCoKdBGA1S/6LohblsDQw+Div8IhZ6ovufQrCnQZ2DYt8oOC1r4CecVw/h/hyH+BpOSwKxPpMQW6DExlH8GLt8GKJyBrsL+HZ8k3ICU97MpE9pkCXQaW6s3w8u3w7l8gNRNO+zGcfK36kktCUKDLwLCjEl7/LSz4I7S1+qlsJ/1AsyBKQlGgS2Jrqoe3/ujDvKEajroQTr8ZCsaFXZlIzCnQJTG1tsC7/+v7ktdsgYPP9H3Jhx8RdmUicaNAl8TinL/Q+eJtUL4KRp8AX5kBY08OuzKRuFOgS2JovxHzK7+Cze/CkEPhoofgU1PVl1wGjGjuKToDOAfY5pzr9u9VM/s0MA+4yDn3SOxKFNmDtjb44El49dewdZmfl/y8e+Hoi9SXXAacaM7QZwJ3A7O628DMkoFfAc/GpiyRvWhrheWPwau/gdL3ofBA+NIf/KAg3YhZBqhobhL9qpmN28tm1wGPAp+OQU0i3WttgWV/g9fu8G3kQybAlx+Aw8/XGbkMePvdhm5mo4DzgdNRoEu8tDTBkv+D1+6E7R/DsCPhX/4Mh35Rt3wTCcTioujvgJucc222l4tPZjYNmAZQXFwcg11Lwmtu8N0PX/8dVG+Ekcf6Yfq62Cmym1gEegkwOwjzIuBsM2txzj3eeUPn3HRgOkBJSYmLwb4lUTXVw6KZ8MZdULsVxpwI594FB01RkIt0Y78D3Tk3vv2xmc0EnuoqzEWi0lgLb98P8+6GulIYNwkumA7jT1WQi+xFNN0WHwImA0VmthG4FUgFcM7dF9fqZOBoqPL37Jx/j5935YDT4bQfaUCQSA9E08vl4mh/mHPuiv2qRgae+gp/387590FjlR+if9qPYHRJ2JWJ9DsaKSrhqCvzzSpv/QmaamHCOXDqD2HkMWFXJtJvKdCld9VshTf/GxbOgOYdvv/4qT+AYYeHXZlIv6dAl95RtdH3WFn0Z2hr8SM6J90IQw4JuzKRhKFAl/iqXOfnIn/3QcDB0RfDpBug8ICwKxNJOAp0iY/y1X54/pLZfkj+cV+DU74H+RpQJhIvCnSJrW0fwGu/gfceheQ0f6u3z1wPg0aGXZlIwlOgS2xsXeZnPlzxBKRmwcRrYOJ1kDss7MpEBgwFuuw752DV87774ZqXIS3Xt4+fdA1kDw67OpEBR4EuPdfcAEv/CvPvhdIPIHcETLkVSq6EzIKwqxMZsBToEr26Mj/Pylt/gvoyGH4knP9HOPwCSEkLuzqRAU+BLntX+iHMu8f3WGlt9MPzT77WT5ylCbNE+gwFunTNOVj7ig/yj56FlAw45mLfPq7BQCJ9kgJddtXS5LsczrsHPlkG2UNg8s3w6asguyjs6kRkDxTo4tVXwKL/8VPY1m719+r84n/DkRdCakbY1YlIFBToA135apj/B1j8IDTX+3nIz7tHdwYS6YcU6AORc7B+nm9W+eDvkJQCR13oBwNp1kORfkuBPpC0tsCKx32Qb37H9xmfdKMfnp87POzqRGQ/KdAHgoYqeGcWLPgjVG2AwgPhC3fA0ZdAWlbY1YlIjCjQE9n29f7Wbu/MgqYaGHsKnP1r3488KSns6kQkxqK5SfQM4Bxgm3PuiC7WXwrcBBhQA3zbObck1oVKD2xc6OdXWfEEYHDEBb59fOSxYVcmInEUzRn6TOBuYFY369cCpznnKs1sKjAdODE25UnU2lr9Bc5598CG+ZCeBxOvhRO/CXmjw65ORHrBXgPdOfeqmY3bw/o3I57OB5Qevamx1nc5nH+vvztQfjGcdTscexmk54ZdnYj0oli3oV8FPNPdSjObBkwDKC7WnWv2yycr/I2Wl8z27eOjT4DP/gwmnAPJujQiMhDF7H++mZ2OD/RTutvGOTcd3yRDSUmJi9W+B4yWRlgxFxY+4PuRJ6fD4V+CT18NY04IuzoRCVlMAt3MjgLuB6Y658pj8TMlQsVaPyz/3b9AfTkUjIfP3QbHXKobSYhIh/0OdDMrBuYAlzvnVu5/SQL4QUAf/RPefgBWvwCWDJ+aCiXf8MPz1e1QRDqJptviQ8BkoMjMNgK3AqkAzrn7gFuAwcC95uf+aHHOlcSr4IRXvcX3G3/nz1C9yd8N6LQfw3Ffg7xRYVcnIn1YNL1cLt7L+quBq2NW0UDU1ubnHl84w3c9dK3+LHzqr+CQsyA5NewKRaQfUHeIMNVXwOL/80FesdrPrTLxO3D8lTD4wLCrE5F+RoHe25zzIzkXzoDlc6ClAcacCKf9CA77kuYeF5F9pkDvLY21sOxh3+Vw6zJIy4FjLvEXOYcfGXZ1IpIAFOjx9skKH+JL/uoHAA07Ar5wp59/XCM5RSSGFOjx0NLoJ8Z6+wE/r0pyOhx+vj8bH3OC7gQkInGhQI+lijWwaKYGAIlIKBTo+6u7AUCfvgrGT9YAIBHpNQr0fVW1yZ+JdwwAGgmTf+IHAA0aGXZ1IjIAKdB7oqneD/xZ8n+w+iXAwYFnwNT/CgYA6XCKSHiUQHvjHGx4y885vvwxaKyGvGI49YdwzMVQeEDYFYqIAAr07m3fAEtnw+KH/CjO1Cw47Dzfd3zsKWobF5E+R4EeqakePnjKn42veQVwPrwn3QiHfVH9xkWkT1OgOwfr5wdNKo/7wT/5xXDaTXD0RVA4PuwKRUSiMnADfft6P3pz8YNQuRZSs/3df465BIpPVpOKiPQ7AyvQm+rg/Sd9iK991S8bN8lPjHXoFyE9J9z6RET2Q+IHunPw8Zu+q+Hyx6GpFvLHwuSbfZNKwdiwKxQRiYnEDfTKj2HJbB/klev87IaHtTepTFSTiogknMQK9MZaeH+uv2nEutf8svGn+hGch54Ladnh1iciEkfR3FN0BnAOsM05d0QX6w24CzgbqAeucM69E+tCu9XWBuvf9CG+/HForvOTYp3+U9+kkl/ca6WIiIQpmjP0mcDdwKxu1k8FDg6+TgT+EHyPr4q1QZPKQ7D9Y0jLhSMu8DMbFp+kKWpFZMCJ5ibRr5rZuD1sch4wyznngPlmlm9mI5xzW2JU4y4+Wvgc7oXbOGTHEhxGzYiTsZNvIueYL2FqUhGRASwWbeijgA0RzzcGy3YLdDObBkwDKC7et6aQ6oZWhjVs446WC3m05RQ2ry2CtZD799cZV5TN+KLs4HsW4wb75/lZafu0LxGR/qRXL4o656YD0wFKSkrcvvyM4z9zJnzmfb7b5rigcgfryupYW1bHunL//Z31lTy5dDMu4qfnZ6V2hHtH4A/OZlxRFrkZqTH5t4mIhC0Wgb4JGBPxfHSwLD6CtvHUZOsI6NM7bdLY0sqGinrWltX7wC+vY21pHfPXlPPYu7uWVpSTxrjB2R1n9+OLsoPnWWSlJVYnIBFJbLFIrLnAtWY2G38xtCpe7efRSk9J5qChuRw0dPfJtHY0tfJxRV1wZl/fcYb/yspSHlm0cZdthw1K7zizjwz84sIsMlKTe+ufIyISlWi6LT4ETAaKzGwjcCuQCuCcuw94Gt9lcRW+2+KV8So2FjLTkpkwfBAThg/abV1tYwvrguab9sBfW1bLsys+oaKuqWM7MxiZl8m4oizGFGQxptB/FRdmMaYgk8LsNEy9bESkl5lz+9SUvd9KSkrcwoULQ9n3vqja0dwR9mvLgsAvr2djRT3lEWEPkJ2W3BHyYwqyKC7M7Aj80QVZZKbp7F5E9o2ZLXLOlXS1To3EUcrLTOXoMfkcPSZ/t3V1jS1sqKxnQ8UO1lfUsyH4+ri8jtc+KqWhuW2X7YfkpjOmINOf0UcG/+Ashg/KIDlJZ/ci0nMK9BjITk/pthnHOUdZbRPrK+rZWFnP+vL6jvB/e10lc5dspi3ij6TUZGNUfmanM/wsxhT6D4C8zFQ154hIlxTocWZmDMlNZ0huOsePLdhtfXNrG5u379h5dl9Z78O/op5nlm2hsr55l+1z01N2ttcHIT+6IIuR+ZmMKsgkJ12/UpGBSv/7Q5aanMTYwdmMHdz1KNeahmY2VOwIzur91/qKelaV1vLSh9tobNm1OWdQRooP9yDgR+ZnBs8zGJWfxZDcdDXpiCQoBXofl5uRymEjUzls5O7NOW1tjtLaRjZW7mDzdv+1qeN7Aws/rqRqx65n+ClJxvC8DEbmZzI6f2fgj8zPYHTwAaD+9yL9k/7n9mNJScawQRkMG5TRZXMO+DP8LVUNO4O+I/wbWLC2gq3VDbS27drTKT8rlZF5/gx/VBD2o/Kzgu+ZFOWkk6SzfJE+R4Ge4HIzUsnNSOWQYbsPsgJoaW1jW01jx9l9e/Bv3t7Ahop65q8up6axZZfXpCUnMSI/g5F5Ec05BZkMz8tk+KAMhudlMCgjRRdvRXqZAn2AS0lO6mh26bJjK1Dd0BzRpNMQcZa/g3mry9ha3UCnk3wyU5MZnpfREfDDBmUwIvg+PM8/LspRe75ILCnQZa8GZaQyaHhql90ywffU2VrVwCfVDWwJvm+tamBLdQOfVDXw9roKPqluoLl119RPTjKG5KTvEvztj9s/AIbnZWiaBZEoKdBlv6UmJ3X0m+9OW5ujor6JrVU+7LdW7/z+SXUDq0preWNV2W7NO+AHdXWc3XcK/vbv+Vnqny+iQJdekZRkFOWkU5STzhGj8rrdrraxpeNsv3Pwb61qYMWWaspqG+k8Y0V6SlJH087Q3HSG5mYwdFA6Q4MxAENz/XIFvyQyBbr0KTnpKRw0NIeDhuZ0u01zcCG3q2aerVUNvLepim0126hvat3ttWnJSQzJTacoNz0I/p3hPyQnPfgQyKAoJ42U5KR4/lNFYk6BLv1OanKSHziVn7nH7WobWyitaWRbdQPbahqDrwZKaxoprWlkfXk9C9dV7DYaF/yMmoVZaf7svuOsP+Jsf9DODwNNtiZ9hQJdElZOego56SmML9rzvWabWtooqw0CPyL8ffD75yu31lBW20hL5+48wX46wn5QRseZvm9iSutoairMTiMtRWf9Ej8KdBnw0lJ2dt3ck7Y2R2V9086z/SD828/4t9U0sHTjdrZVN7KjeffmHvAXeIty0hic45t4BkcE/s7H/nu25uWRHtI7RiRKSUnG4Jx0Buekc+iI7rdzzlHX1EpZTSPldY2U1jRRXtdIWU0TZbWNHY/f31pNWU0j1Q279+wB35e/c8hHBv/gnDSGBMvyMlM1elcU6CKxZmYdzT3j9tLcA/4euBV1TT7w6xopq2mkrLaJ8trG4AOgiY2VO1i8oYqKusbdBnGBn6OnMNuf+RcFQT84+EugMDuNwdlpFEZ85aRrJG8iUqCLhCw9JZkReZmMyNtzkw/sbPYpr2vywd/+vbaR8lr/F0BZXRNrSusoq23cbTbOdmnJSRRmp1HQRdi3fwBErsvPStOo3n4gqkA3s7OAu4Bk4H7n3O2d1hcDfwbyg21+7Jx7Osa1igx4kc0+3c3P06696aeyzn8AVNT50G//QKiobaKiromK+iY2VNZTUdvU5cAu8L1+8jNTg7BP3/OHQU4aBVlpGuEbgmhuEp0M3AN8DtgIvG1mc51zKyI2+zfgb865P5jZYfgbR4+LQ70iEqXIpp89jeKN1NTS5gM/IuwrahupCD4U2tetLq2lYp1/3lUTEPh76xbmpFGYnU5hVioFWf5MvyArlfzsNArbH2elUZCdqg+BGIjmDP0EYJVzbg2Amc0GzgMiA90B7RN95AGbY1mkiPSOtJSkjimZo9HW5qja0bxL2FcEfw1U1DX7vwrqmiitbWTlJ7Vsr2+irosBX+0yUpMobA/+7NSOD4CCLH/Wv3PZzg8Dzey5UzSBPgrYEPF8I3Bip23+A3jWzK4DsoHPdvWDzGwaMA2guLi4p7WKSB+TlGQUBM0v0WpsaWV7fTOV9U1U1jWzvb6JyuD59vomKjqWNbFle7VfvqN5t+ke2qUkGflZO8O/40Mge9fgb3+cl5VKXmYq6SmJ99dArC6KXgzMdM7dYWYTgf81syOcc7tckXHOTQemA5SUlHTz6xGRRJaeksywQclR/xUA0NrmqN4RfAjU7/wQaA/+yA+BDRX1LN3o1zd1c1EYICstmfzMVAZlpvoPhMw08oPAb3+cn+nDPy/4UMjPTCUrLbnP/kUQTaBvAsZEPB8dLIt0FXAWgHNunpllAEXAtlgUKSIDW/I+/CXgnKO+qTU482/u+L59RzNVEY+31zdTtcNfF6gKnje1dv9BkJps5EUEfn5W8KHQviz4C/jPNwoAAAaISURBVKD9A6D9eW5Gatx7CkUT6G8DB5vZeHyQXwRc0mmb9cAUYKaZHQpkAKWxLFREpCfMjOz0FLLTUxjd9R0au+Sco6G5je07gtAPAn/XD4CdyzZvb+D9LTV7vT5g5u8tkJ+VyuUnjeXqSQfE4F+5q70GunOuxcyuBf6J75I4wzm33Mx+Dix0zs0FbgT+ZGbfx18gvcK57lq8RET6LjMjMy2ZzLToxgZEampp2yXs28O/46+C4ANhSG56fGoPK3dLSkrcwoULQ9m3iEh/ZWaLnHNd3jFSU7+JiCQIBbqISIJQoIuIJAgFuohIglCgi4gkCAW6iEiCUKCLiCQIBbqISIIIbWCRmZUCH+/jy4uAshiWEyt9tS7ou7Wprp5RXT2TiHWNdc4N6WpFaIG+P8xsYXcjpcLUV+uCvlub6uoZ1dUzA60uNbmIiCQIBbqISILor4E+PewCutFX64K+W5vq6hnV1TMDqq5+2YYuIiK7669n6CIi0okCXUQkQfS5QDezs8zsQzNbZWY/7mJ9upn9NVi/wMzGRaz7SbD8QzM7s5frusHMVpjZUjN7wczGRqxrNbPFwdfcXq7rCjMrjdj/1RHrvm5mHwVfX+/lun4bUdNKM9sesS6ex2uGmW0zs/e6WW9m9vug7qVmdlzEunger73VdWlQzzIze9PMjo5Yty5YvtjMYnrXmCjqmmxmVRG/r1si1u3xPRDnun4YUdN7wXuqMFgXl+NlZmPM7KUgB5ab2fVdbBPf95dzrs984W9xtxo4AEgDlgCHddrmO8B9weOLgL8Gjw8Ltk8Hxgc/J7kX6zodyAoef7u9ruB5bYjH6wrg7i5eWwisCb4XBI8LequuTttfh7+1YVyPV/CzTwWOA97rZv3ZwDOAAScBC+J9vKKs6+T2/QFT2+sKnq8DikI6XpOBp/b3PRDrujptey7wYryPFzACOC54nAus7OL/Y1zfX33tDP0EYJVzbo1zrgmYDZzXaZvzgD8Hjx8BppiZBctnO+canXNrgVXBz+uVupxzLznn6oOn84HRMdr3ftW1B2cCzznnKpxzlcBzwFkh1XUx8FCM9r1HzrlXgYo9bHIeMMt584F8MxtBfI/XXutyzr0Z7Bd67/0VzfHqzv68N2NdV6+8v5xzW5xz7wSPa4D3gVGdNovr+6uvBfooYEPE843sfkA6tnHOtQBVwOAoXxvPuiJdhf8UbpdhZgvNbL6ZfSlGNfWkri8Hf949YmZjevjaeNZF0DQ1HngxYnG8jlc0uqs9nserpzq/vxzwrJktMrNpIdQz0cyWmNkzZnZ4sKxPHC8zy8IH46MRi+N+vMw3BR8LLOi0Kq7vr5SevkD2zMwuA0qA0yIWj3XObTKzA4AXzWyZc251L5X0JPCQc67RzL6J/+vmjF7adzQuAh5xzrVGLAvzePVpZnY6PtBPiVh8SnC8hgLPmdkHwRlsb3gH//uqNbOzgceBg3tp39E4F3jDORd5Nh/X42VmOfgPkO8556pj9XOj0dfO0DcBYyKejw6WdbmNmaUAeUB5lK+NZ12Y2WeBnwJfdM41ti93zm0Kvq8BXsZ/cvdKXc658oha7geOj/a18awrwkV0+nM4jscrGt3VHs/jFRUzOwr/OzzPOVfevjzieG0DHiN2TY175Zyrds7VBo+fBlLNrIg+cLwCe3p/xfx4mVkqPswfdM7N6WKT+L6/Yn1hYD8vKqTgLwaMZ+eFlMM7bXMNu14U/Vvw+HB2vSi6hthdFI2mrmPxF4EO7rS8AEgPHhcBHxGji0NR1jUi4vH5wHy38yLM2qC+guBxYW/VFWw3AX+BynrjeEXsYxzdX+T7ArtetHor3scryrqK8deFTu60PBvIjXj8JnBWL9Y1vP33hw/G9cGxi+o9EK+6gvV5+Hb27N44XsG/exbwuz1sE9f3V8wObgx/SWfjrw6vBn4aLPs5/qwXIAN4OHhzvwUcEPHanwav+xCY2st1PQ98AiwOvuYGy08GlgVv6GXAVb1c1y+B5cH+XwImRLz2G8FxXAVc2Zt1Bc//A7i90+vifbweArYAzfh2yquAbwHfCtYbcE9Q9zKgpJeO197quh+ojHh/LQyWHxAcqyXB7/mnvVzXtRHvr/lEfOB09R7orbqCba7Ad5SIfF3cjhe+GcwBSyN+T2f35vtLQ/9FRBJEX2tDFxGRfaRAFxFJEAp0EZEEoUAXEUkQCnQRkQShQBcRSRAKdBGRBPH/AQrayXPgXuKvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xx = x.tolist()\n",
    "yy = Psi_t(x)[:,0].tolist()\n",
    "yt = Psi_real(x).tolist()\n",
    "ax.plot(xx, yy)\n",
    "ax.plot(xx,yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is tensor(0.2987, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2986593544483185"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "'''\n",
    "    Pure Python/Numpy implementation of the Nelder-Mead algorithm.\n",
    "    Reference: https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method\n",
    "'''\n",
    "\n",
    "\n",
    "def nelder_mead(f, x_start,\n",
    "                step=0.1, no_improve_thr=10e-6,\n",
    "                no_improv_break=10, max_iter=0,\n",
    "                alpha=1., gamma=2., rho=-0.5, sigma=0.5):\n",
    "    '''\n",
    "        @param f (function): function to optimize, must return a scalar score\n",
    "            and operate over a numpy array of the same dimensions as x_start\n",
    "        @param x_start (numpy array): initial position\n",
    "        @param step (float): look-around radius in initial step\n",
    "        @no_improv_thr,  no_improv_break (float, int): break after no_improv_break iterations with\n",
    "            an improvement lower than no_improv_thr\n",
    "        @max_iter (int): always break after this number of iterations.\n",
    "            Set it to 0 to loop indefinitely.\n",
    "        @alpha, gamma, rho, sigma (floats): parameters of the algorithm\n",
    "            (see Wikipedia page for reference)\n",
    "        return: tuple (best parameter array, best score)\n",
    "    '''\n",
    "\n",
    "    # init\n",
    "    dim = len(x_start)\n",
    "    prev_best = f(x_start)\n",
    "    no_improv = 0\n",
    "    res = [[x_start, prev_best]]\n",
    "\n",
    "    for i in range(dim):\n",
    "        x = copy.copy(x_start)\n",
    "        x[i] = x[i] + step\n",
    "        score = f(x)\n",
    "        res.append([x, score])\n",
    "\n",
    "    # simplex iter\n",
    "    iters = 0\n",
    "    while 1:\n",
    "        # order\n",
    "        res.sort(key=lambda x: x[1])\n",
    "        best = res[0][1]\n",
    "\n",
    "        # break after max_iter\n",
    "        if max_iter and iters >= max_iter:\n",
    "            return res[0]\n",
    "        iters += 1\n",
    "\n",
    "        # break after no_improv_break iterations with no improvement\n",
    "        print('...best so far:', best)\n",
    "\n",
    "        if best < prev_best - no_improve_thr:\n",
    "            no_improv = 0\n",
    "            prev_best = best\n",
    "        else:\n",
    "            no_improv += 1\n",
    "\n",
    "        if no_improv >= no_improv_break:\n",
    "            return res[0]\n",
    "\n",
    "        # centroid\n",
    "        x0 = [0.] * dim\n",
    "        for tup in res[:-1]:\n",
    "            for i, c in enumerate(tup[0]):\n",
    "                x0[i] += c / (len(res)-1)\n",
    "\n",
    "        # reflection\n",
    "        xr = x0 + alpha*(x0 - res[-1][0])\n",
    "        rscore = f(xr)\n",
    "        if res[0][1] <= rscore < res[-2][1]:\n",
    "            del res[-1]\n",
    "            res.append([xr, rscore])\n",
    "            continue\n",
    "\n",
    "        # expansion\n",
    "        if rscore < res[0][1]:\n",
    "            xe = x0 + gamma*(x0 - res[-1][0])\n",
    "            escore = f(xe)\n",
    "            if escore < rscore:\n",
    "                del res[-1]\n",
    "                res.append([xe, escore])\n",
    "                continue\n",
    "            else:\n",
    "                del res[-1]\n",
    "                res.append([xr, rscore])\n",
    "                continue\n",
    "\n",
    "        # contraction\n",
    "        xc = x0 + rho*(x0 - res[-1][0])\n",
    "        cscore = f(xc)\n",
    "        if cscore < res[-1][1]:\n",
    "            del res[-1]\n",
    "            res.append([xc, cscore])\n",
    "            continue\n",
    "\n",
    "        # reduction\n",
    "        x1 = res[0][0]\n",
    "        nres = []\n",
    "        for tup in res:\n",
    "            redx = x1 + sigma*(tup[0] - x1)\n",
    "            score = f(redx)\n",
    "            nres.append([redx, score])\n",
    "        res = nres\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # test\n",
    "    import math\n",
    "    import numpy as np\n",
    "\n",
    "    def f(x):\n",
    "        return math.sin(x[0]) * math.cos(x[1]) * (1. / (abs(x[2]) + 1))\n",
    "    def g(x):\n",
    "        return x**2+2\n",
    "    \n",
    "    \n",
    "n_points = 10\n",
    "x_train = np.linspace(0, 2, n_points)[:, None]       # Train from 0 to 2\n",
    "x_train = torch.Tensor(x_train)\n",
    "x_train.requires_grad = True\n",
    "\n",
    "n_rectangles = 100\n",
    "\n",
    "def loss_op(fin_weights): \n",
    "    ''' x will be the vector of weights and bias'''\n",
    "\n",
    "    nr_nodes = int(len(fin_weights)/3)\n",
    "    w_i = fin_weights[0:nr_nodes]\n",
    "    u_i = fin_weights[nr_nodes:nr_nodes*2]\n",
    "    v_i = fin_weights[nr_nodes*2:]\n",
    "\n",
    "    # Setting the weights of the Neural network to these new values (in the iteration process of \n",
    "    # the optimization)\n",
    "    with torch.no_grad():\n",
    "        for i in range(nr_nodes):\n",
    "            N[0].weight[i,0] = w_i[i]\n",
    "            N[0].bias[i] = u_i[i]\n",
    "            N[2].weight[0,i] = v_i[i]\n",
    "\n",
    "    outputs = Psi_t(x_train) \n",
    "    integrals_vector = torch.tensor([[Trapez(i, n_rectangles) for i in x_train[:,0].tolist()]]) + 1\n",
    "\n",
    "    final_loss = torch.mean( (outputs - integrals_vector) ** 2) # Tensor\n",
    "    final_loss = final_loss.tolist()  # Number float and not anymore a tensor\n",
    "    return final_loss\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...best so far: 0.2425534874200821\n",
      "...best so far: 0.2425534874200821\n",
      "...best so far: 0.2425534874200821\n",
      "...best so far: 0.2425534874200821\n",
      "...best so far: 0.2425534874200821\n",
      "...best so far: 0.2425534874200821\n",
      "...best so far: 0.2425534874200821\n",
      "...best so far: 0.2425534874200821\n",
      "...best so far: 0.2425534874200821\n",
      "...best so far: 0.2425534874200821\n",
      "...best so far: 0.2425534874200821\n",
      "[array([ 0.03516897, -0.20227772, -0.32447407,  0.85264856,  0.70549333,\n",
      "       -0.49257341, -0.56238514,  0.4185631 , -0.00307636, -0.53804362,\n",
      "       -0.12697111, -0.87731928, -0.38140124, -0.55020881,  0.14679781,\n",
      "        0.33951074,  0.61665636, -0.94746149,  0.09093402,  0.62578601,\n",
      "       -0.46648502,  0.83648211,  0.01150107, -0.57231265, -0.18463491,\n",
      "        0.42764086, -0.41212842,  0.57499987,  0.0697899 , -0.54865634,\n",
      "        0.01305789,  0.0236926 ,  0.02610296, -0.14477161,  0.20065066,\n",
      "       -0.22344093, -0.12050518, -0.07898401, -0.13880591,  0.07508704,\n",
      "       -0.10027942, -0.14867127,  0.2720015 , -0.1363553 ,  0.14094308]), 0.2425534874200821]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    w_i = N[0].weight[:,0].tolist()\n",
    "    u_i = N[0].bias.tolist()\n",
    "    v_i = N[2].weight[0,:].tolist()\n",
    "    weig = np.array(w_i + u_i + v_i)\n",
    "\n",
    "    print(nelder_mead(loss_op, weig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fin_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8e8efa2d836b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnr_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnr_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mw_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnr_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mu_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnr_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnr_nodes\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mv_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnr_nodes\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fin_weights' is not defined"
     ]
    }
   ],
   "source": [
    "nr_nodes = int(len(fin_weights)/3)\n",
    "print(nr_nodes)\n",
    "w_i = fin_weights[0:nr_nodes]\n",
    "u_i = fin_weights[nr_nodes:nr_nodes*2]\n",
    "v_i = fin_weights[nr_nodes*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_weights[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N[0].weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N[0].bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # model[0].weight = nn.Parameter(torch.ones_like(model[0].weight))\n",
    "    # model[0].weight[0, 0] = 2.\n",
    "    # model[0].weight.fill_(3.)\n",
    "    N[2].weight[0,1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
