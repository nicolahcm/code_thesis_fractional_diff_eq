{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# He uses 3 layers, with the hidden layers that uses 5 nodes\n",
    "\n",
    "We will denote by $\\Omega$, the set of weights of the neural Network, that is\n",
    "\n",
    "$$\\Omega = \\left\\{ v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4 \\right\\} $$\n",
    "\n",
    "And $$N(x,\\Omega) = \\sum_{j=1}^5 v_j\\phi(w_jx+u_j) $$\n",
    "\n",
    "Where we use $5$ hidden nodes and one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigm_fun(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def phi_prime(z): #1st derivative\n",
    "    result = np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    return result\n",
    "\n",
    "def phi_second(z): #2nd derivative\n",
    "    first_addend = -np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    second_addend = 2*np.exp(-2*z)/((1+np.exp(-z))**3)\n",
    "    return first_addend + second_addend\n",
    "\n",
    "# Usa *args, come input e spacchetta\n",
    "\n",
    "def compute_neural_network(x,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4):\n",
    "    ''' NN '''\n",
    "    result = v0*sigm_fun(w0*x+u0)\n",
    "    result += v1*sigm_fun(w1*x+u1)\n",
    "    result += v2*sigm_fun(w2*x+u2)\n",
    "    result += v3*sigm_fun(w3*x+u3)\n",
    "    result += v4*sigm_fun(w4*x+u4)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.42641287 -9.58496101  2.6729647   4.97607765 -0.02985975 -5.50406709\n",
      " -6.0387427   5.21061424 -6.61778327 -8.23320372  3.70719637  9.06786692\n",
      " -9.92103467  0.24384527  6.25241923]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "sampl = np.random.uniform(low=-10, high=10, size=(15,))\n",
    "v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4 = sampl\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2171753884110106"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_neural_network(2,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tricks for writing better code... Later\n",
    "\n",
    "Usa *args, come input e spacchetta\n",
    "\n",
    "def comp_neur_net(x,*weights):\n",
    "    for i in weights:\n",
    "        print(i)\n",
    "\n",
    "comp_neur_net(2,*(v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4))\n",
    "\n",
    "----\n",
    "\n",
    "my_vars = {}\n",
    "for i in range(10):\n",
    "    var_name = \"var%d\" % i\n",
    "    my_vars[var_name] = i\n",
    "\n",
    "print(my_vars[\"var2\"])\n",
    "\n",
    "This is equivalent to creating var0 = 0, var1 = 1, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First example in the paper of Mall, Charkaverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.434350776822021"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def y_n(x,*weights):\n",
    "    return x*compute_neural_network(x,*weights)\n",
    "y_n(2,*(v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Computing E (we need alpha-derivative)\n",
    "\n",
    "we take $10$ equidistant points\n",
    "\n",
    "$$E[weights] = \\sum_{i=1}^{10} [D^\\alpha y_N(x_i,weights) - f(x_i, y_N(x_i,weights))]^2 =$$ \n",
    "\n",
    "$$=\\sum_{i=1}^{10} addend-in-E-w $$\n",
    "how it is named in the code below\n",
    "\n",
    "where \n",
    "\n",
    "$$ D^\\alpha y(x) = x$$\n",
    "\n",
    "so $f(x,weights) = x$\n",
    "\n",
    "then \n",
    "\n",
    "$$ y_N(x,weights) = xN(x,weights)$$\n",
    "\n",
    "Moreover, \n",
    "\n",
    "$$ D_x^\\alpha (N) := D_x^\\alpha N(x,weights) = \\sum_{j=1}^5 v_j \\phi'(w_jx+u_j)w_jx^{1-\\alpha} $$\n",
    "\n",
    "So that we get, if $x_0=0$ (centered in $0$ the initial condition)\n",
    "\n",
    "$$D_x^\\alpha y_N(x,weights) = D_x^\\alpha (xN) = x^{1-\\alpha}N + xD_x^\\alpha (N) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 equidistant points between 0 and 1 included\n",
    "# np.linspace(0,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_alpha_y_N(x,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4): # Depends on the fDe\n",
    "\n",
    "    first_addend = x**(1-alp)*compute_neural_network(x,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)\n",
    "\n",
    "    def der_alpha_N(alp,x,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4):\n",
    "\n",
    "        tot_sum = v0*phi_prime(w0*x+u0)*w0*x**(1-alp)\n",
    "        tot_sum += v1*phi_prime(w1*x+u1)*w1*x**(1-alp)\n",
    "        tot_sum += v2*phi_prime(w2*x+u2)*w2*x**(1-alp)\n",
    "        tot_sum += v3*phi_prime(w3*x+u3)*w3*x**(1-alp)\n",
    "        tot_sum += v4*phi_prime(w4*x+u4)*w4*x**(1-alp)\n",
    "\n",
    "        return tot_sum\n",
    "\n",
    "    second_addend = x*der_alpha_N(alp,x,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)\n",
    "\n",
    "    return first_addend + second_addend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_to_evaluate = np.linspace(0,1,50)\n",
    "\n",
    "def E(alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4,points_to_evaluate=points_to_evaluate): #E[weights]\n",
    "    ''' \n",
    "    returns the value of E, knowing \n",
    "    alpha, weights of the NN, and the points_to_evaluate.\n",
    "    '''\n",
    "    \n",
    "    def addend_in_E_w(x,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4):\n",
    "        \n",
    "        def f_x_i_y_N(x): # In this special case is x\n",
    "            return x\n",
    "        \n",
    "        return (der_alpha_y_N(x,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4) - f_x_i_y_N(x))**2\n",
    "    \n",
    "    tot_sum = 0\n",
    "    for x in points_to_evaluate:\n",
    "        tot_sum += addend_in_E_w(x,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)\n",
    "    \n",
    "    return tot_sum\n",
    "\n",
    "# Check again that the function is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3124.747807239304"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha = 0.5\n",
    "E(0.5,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Compute partial derivatives of E wrt to the weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that \n",
    "$$ D_x^\\alpha (N) := D_x^\\alpha N(x,weights) = \\sum_{j=1}^5 v_j \\phi'(w_jx+u_j)w_jx^{1-\\alpha} $$.\n",
    "\n",
    "Thus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start by computing derivative of E wrt to w_k\n",
    "\n",
    "$$\\frac{\\partial E[weights]}{\\partial w_k} = \\sum_{j=1}^{10} 2[D^\\alpha y_N(x_i,weights) - f(x_i, y_N(x_i,weights))] [\\frac{\\partial D^\\alpha y_N}{\\partial w_k}-\\frac{\\partial f}{\\partial w_k}]$$\n",
    "\n",
    "In the first example in the paper of Mall, $f(x,y_N(x,weights)) = x$. Thus $\\frac{\\partial f}{\\partial w_k}=0$ .\n",
    "\n",
    "Moreover, we use equation 16 from the paper of Mall. We remember that in this particular case we have\n",
    "\n",
    "$$ y_N(x,weights) = xN(x,weights)$$\n",
    "\n",
    "that is \n",
    "\n",
    "$$D_x^\\alpha y_N(x,weights) = D_x^\\alpha (xN) = x^{1-\\alpha}N + xD_x^\\alpha (N) $$\n",
    "\n",
    "so that from eq.16, we get\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial D^\\alpha y_N}{\\partial w_k} =x^{1-\\alpha}\\frac{\\partial N}{\\partial w_k} + x\\frac{\\partial D_x^\\alpha (N)}{\\partial w_k} = x^{1-\\alpha}\\frac{\\partial N}{\\partial w_k} + x(v_kx^{1-\\alpha}(\\phi'(w_kx+u_k) + \\phi''(w_kx+u_k) w_kx))\n",
    "\\end{equation}\n",
    "\n",
    "It is left to compute $\\frac{\\partial N}{\\partial w_k}$. We remind that $N=\\sum_{j=1}^5 v_j\\phi(w_jx+u_j)$. So that we get $\\frac{\\partial N}{\\partial w_k}= v_k\\phi'(w_kx+u_k)x$. So that we get \n",
    "\n",
    "$$\\frac{\\partial D^\\alpha y_N}{\\partial w_k} = x^{2-\\alpha}v_k\\phi'(w_kx+u_k) + (v_kx^{2-\\alpha}(\\phi'(w_kx+u_k) + \\phi''(w_kx+u_k) w_kx)) $$\n",
    "\n",
    "And finally\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_k} = \\sum_{j=1}^{10} 2[D^\\alpha y_N(x_i,weights) - f(x_i, y_N(x_i,weights))] [\\frac{\\partial D^\\alpha y_N}{\\partial w_k}] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the derivative of E wrt to w1, evaluated 486.8661468581863\n"
     ]
    }
   ],
   "source": [
    "def der_E_wrt_wj(alp,j,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4,points_to_evaluate=points_to_evaluate):\n",
    "    ''' As input, exactly the parameters of the function E'''\n",
    "    \n",
    "    def addend_in_E_wrt_wj(x,j,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4):\n",
    "        \n",
    "        def f_x_i_y_N(x): # In this special case is x\n",
    "            return x\n",
    "        \n",
    "        def der_D_alpha_y_N_wrt_wj(j):\n",
    "            if j==0:\n",
    "                first_addend = x**(2-alp)*v0*phi_prime(w0*x+u0)\n",
    "                second_addend = v0*x**(2-alp)*(phi_prime(w0*x+u0) + phi_second(w0*x+u0)*w0*x)\n",
    "            if j==1:\n",
    "                first_addend = x**(2-alp)*v1*phi_prime(w1*x+u1)\n",
    "                second_addend = v1*x**(2-alp)*(phi_prime(w1*x+u1) + phi_second(w1*x+u1)*w1*x)\n",
    "            if j==2:\n",
    "                first_addend = x**(2-alp)*v2*phi_prime(w2*x+u2)\n",
    "                second_addend = v2*x**(2-alp)*(phi_prime(w2*x+u2) + phi_second(w2*x+u2)*w2*x)\n",
    "            if j==3:\n",
    "                first_addend = x**(2-alp)*v3*phi_prime(w3*x+u3)\n",
    "                second_addend = v3*x**(2-alp)*(phi_prime(w3*x+u3) + phi_second(w3*x+u3)*w3*x)\n",
    "            if j==4:\n",
    "                first_addend = x**(2-alp)*v4*phi_prime(w4*x+u4)\n",
    "                second_addend = v4*x**(2-alp)*(phi_prime(w4*x+u4) + phi_second(w4*x+u4)*w4*x)\n",
    "                \n",
    "            return first_addend + second_addend\n",
    "    \n",
    "        return 2*(der_alpha_y_N(x,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4) - f_x_i_y_N(x))*der_D_alpha_y_N_wrt_wj(j)\n",
    "\n",
    "    tot_sum = 0\n",
    "    for x in points_to_evaluate:\n",
    "        tot_sum += addend_in_E_wrt_wj(x,j,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)\n",
    "    \n",
    "    return tot_sum\n",
    "\n",
    "# alpha = 0.5, let's derive wrt. j=2 ---> w2\n",
    "\n",
    "j = 1\n",
    "print(\"this is the derivative of E wrt to w%d, evaluated\"%j,\n",
    "     der_E_wrt_wj(0.7,j,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## derivative of E wrt to v_k\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial v_k} = \\sum_{j=1}^{10} 2[D^\\alpha y_N(x_i,weights) - f(x_i, y_N(x_i,weights))] [\\frac{\\partial D^\\alpha y_N}{\\partial v_k}] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where, $[\\frac{\\partial D^\\alpha y_N}{\\partial v_k}]$ is computed here\n",
    "\n",
    "In our special case, we have\n",
    "\n",
    "$$D_x^\\alpha y_N(x,weights) = D_x^\\alpha (xN) = x^{1-\\alpha}N + xD_x^\\alpha (N) $$\n",
    "\n",
    "So that from eq.17, we get\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial D^\\alpha y_N}{\\partial v_k} =x^{1-\\alpha}\\frac{\\partial N}{\\partial v_k} + x\\frac{\\partial D_x^\\alpha (N)}{\\partial v_k} = x^{1-\\alpha}\\frac{\\partial N}{\\partial v_k} + x\\cdot w_k \\cdot x^{1-\\alpha}\\phi'(w_kx+u_k) \n",
    "\\end{equation}\n",
    "\n",
    "It is left to compute $\\frac{\\partial N}{\\partial v_k}$. We remind that $N=\\sum_{j=1}^5 v_j\\phi(w_jx+u_j)$. So that we get $\\frac{\\partial N}{\\partial v_k}=\\phi(w_kx+u_k)$. So that we get \n",
    "\n",
    "$$\\frac{\\partial D^\\alpha y_N}{\\partial v_k} = x^{1-\\alpha}\\phi(w_kx+u_k) + x^{2-\\alpha}\\phi'(w_kx+u_k) w_k$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the derivative of E wrt to v4, evaluated 263.5734361506602\n"
     ]
    }
   ],
   "source": [
    "def der_E_wrt_vj(alp,j,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4,points_to_evaluate=points_to_evaluate):\n",
    "    ''' As input, exactly the parameters of the function E'''\n",
    "    \n",
    "    def addend_in_E_wrt_vj(x,j,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4):\n",
    "        \n",
    "        def f_x_i_y_N(x): # In this special case is x\n",
    "            return x\n",
    "        \n",
    "        def der_D_alpha_y_N_wrt_vj(j):\n",
    "            if j==0:\n",
    "                first_addend = x**(1-alp)*sigm_fun(w0*x+u0)\n",
    "                second_addend = w0*x**(2-alp)*phi_prime(w0*x+u0)\n",
    "            if j==1:\n",
    "                first_addend = x**(1-alp)*sigm_fun(w1*x+u1)\n",
    "                second_addend = w1*x**(2-alp)*phi_prime(w1*x+u1)\n",
    "            if j==2:\n",
    "                first_addend = x**(1-alp)*sigm_fun(w2*x+u2)\n",
    "                second_addend = w2*x**(2-alp)*phi_prime(w2*x+u2)\n",
    "            if j==3:\n",
    "                first_addend = x**(1-alp)*sigm_fun(w3*x+u3)\n",
    "                second_addend = w3*x**(2-alp)*phi_prime(w3*x+u3)\n",
    "            if j==4:\n",
    "                first_addend = x**(1-alp)*sigm_fun(w4*x+u4)\n",
    "                second_addend = w4*x**(2-alp)*phi_prime(w4*x+u4)\n",
    "\n",
    "            return first_addend + second_addend\n",
    "    \n",
    "        return 2*(der_alpha_y_N(x,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4) - f_x_i_y_N(x))*der_D_alpha_y_N_wrt_vj(j)\n",
    "\n",
    "    tot_sum = 0\n",
    "    for x in points_to_evaluate:\n",
    "        tot_sum += addend_in_E_wrt_vj(x,j,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)\n",
    "    \n",
    "    return tot_sum\n",
    "\n",
    "# alpha = 0.5, let's derive wrt. j=2 ---> v2\n",
    "\n",
    "j = 4\n",
    "print(\"this is the derivative of E wrt to v%d, evaluated\"%j,\n",
    "     der_E_wrt_vj(0.7,j,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## derivative of E wrt to u_k\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial u_k} = \\sum_{j=1}^{10} 2[D^\\alpha y_N(x_i,weights) - f(x_i, y_N(x_i,weights))] [\\frac{\\partial D^\\alpha y_N}{\\partial u_k}] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where, $[\\frac{\\partial D^\\alpha y_N}{\\partial u_k}]$ is computed here\n",
    "\n",
    "In our special case, we have\n",
    "\n",
    "$$D_x^\\alpha y_N(x,weights) = D_x^\\alpha (xN) = x^{1-\\alpha}N + xD_x^\\alpha (N) $$\n",
    "\n",
    "So that from eq.18, we get\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial D^\\alpha y_N}{\\partial u_k} =x^{1-\\alpha}\\frac{\\partial N}{\\partial u_k} + x\\frac{\\partial D_x^\\alpha (N)}{\\partial u_k} = x^{1-\\alpha}\\frac{\\partial N}{\\partial u_k} + x\\cdot w_k\\cdot v_k \\cdot x^{1-\\alpha}\\phi''(w_kx+u_k) \n",
    "\\end{equation}\n",
    "\n",
    "It is left to compute $\\frac{\\partial N}{\\partial u_k}$. We remind that $N=\\sum_{j=1}^5 v_j\\phi(w_jx+u_j)$. So that we get $\\frac{\\partial N}{\\partial u_k}=v_k \\phi'(w_kx+u_k)$. So that we get \n",
    "\n",
    "$$\\frac{\\partial D^\\alpha y_N}{\\partial u_k} = x^{1-\\alpha}v_k\\phi'(w_kx+u_k) + x^{2-\\alpha}\\phi''(w_kx+u_k) w_k v_k$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the derivative of E wrt to u0, evaluated -198.58195765966923\n"
     ]
    }
   ],
   "source": [
    "def der_E_wrt_uj(alp,j,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4,points_to_evaluate=points_to_evaluate):\n",
    "    ''' As input, exactly the parameters of the function E'''\n",
    "    \n",
    "    def addend_in_E_wrt_uj(x,j,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4):\n",
    "        \n",
    "        def f_x_i_y_N(x): # In this special case is x\n",
    "            return x\n",
    "        \n",
    "        def der_D_alpha_y_N_wrt_uj(j):\n",
    "            if j==0:\n",
    "                first_addend = x**(1-alp)*v0*phi_prime(w0*x+u0)\n",
    "                second_addend = w0*v0*x**(2-alp)*phi_second(w0*x+u0)\n",
    "            if j==1:\n",
    "                first_addend = x**(1-alp)*v1*phi_prime(w1*x+u1)\n",
    "                second_addend = w1*v1*x**(2-alp)*phi_second(w1*x+u1)\n",
    "            if j==2:\n",
    "                first_addend = x**(1-alp)*v2*phi_prime(w2*x+u2)\n",
    "                second_addend = w2*v2*x**(2-alp)*phi_second(w2*x+u2)\n",
    "            if j==3:\n",
    "                first_addend = x**(1-alp)*v3*phi_prime(w3*x+u3)\n",
    "                second_addend = w3*v3*x**(2-alp)*phi_second(w3*x+u3)\n",
    "            if j==4:\n",
    "                first_addend = x**(1-alp)*v4*phi_prime(w4*x+u4)\n",
    "                second_addend = w4*v4*x**(2-alp)*phi_second(w4*x+u4)\n",
    "\n",
    "            return first_addend + second_addend\n",
    "    \n",
    "        return 2*(der_alpha_y_N(x,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4) - f_x_i_y_N(x))*der_D_alpha_y_N_wrt_uj(j)\n",
    "\n",
    "    tot_sum = 0\n",
    "    for x in points_to_evaluate:\n",
    "        tot_sum += addend_in_E_wrt_uj(x,j,alp,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)\n",
    "    \n",
    "    return tot_sum\n",
    "\n",
    "# alpha = 0.5, let's derive wrt. j=2 ---> u2\n",
    "\n",
    "j = 0\n",
    "print(\"this is the derivative of E wrt to u%d, evaluated\"%j,\n",
    "     der_E_wrt_uj(0.7,j,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3124.747807239304"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E(0.5,*[v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(alp,h,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4,points_to_evaluate=points_to_evaluate):\n",
    "    ''' Inputs: alpha, h=learning_rate, Omega, points_to_evaluate.\n",
    "        Output: E, and new weights'''\n",
    "    \n",
    "    old_weights = [v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4]\n",
    "    \n",
    "    new_weights = [np.nan]*15  # new weights = [v0',v1',v2',v3',v4',w0',w1',w2',w3',w4',u0',u1',u2',u3',u4']\n",
    "    for j in [0,1,2,3,4]:\n",
    "        vj_new = old_weights[j] - h*der_E_wrt_vj(alp,j,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)\n",
    "        wj_new = old_weights[5+j] - h*der_E_wrt_wj(alp,j,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)\n",
    "        uj_new = old_weights[10+j] - h*der_E_wrt_uj(alp,j,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)\n",
    "        \n",
    "        new_weights[j] = vj_new\n",
    "        new_weights[j+5] = wj_new\n",
    "        new_weights[j+10] = uj_new\n",
    "    \n",
    "    #print(\"old weights = \", old_weights, \"\\n\")\n",
    "    #print(\"new weights = \", new_weights, \"\\n\")\n",
    "    \n",
    "    # Old Value of E and New value\n",
    "    old_val_E = E(alp,*old_weights)\n",
    "    new_val_E = E(alp,*new_weights)\n",
    "    #print(\"old_value_of_E = \", old_val_E)\n",
    "    #print(\"new_value_of_E = \", new_val_E)\n",
    "    \n",
    "    return new_weights, new_val_E, old_val_E\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-27.471392409024133,\n",
       "  108.41098867033658,\n",
       "  4.663178674874452,\n",
       "  -0.5670845632986428,\n",
       "  -52.74454698408023,\n",
       "  79.7420639155642,\n",
       "  -103.41197207644478,\n",
       "  10.619175511473236,\n",
       "  -13.986801808984588,\n",
       "  -8.67721183659582,\n",
       "  43.4235878992898,\n",
       "  -86.2186030647713,\n",
       "  -4.652611290418733,\n",
       "  -22.597485248715433,\n",
       "  5.96219728262189],\n",
       " 56046.42651228375,\n",
       " 3568.299138316662)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_rate = 0.2\n",
    "alp = 0.7\n",
    "\n",
    "update_weights(alp,learn_rate,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_updation_of_weights(nr_iterations,alp,learn_rate,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4):\n",
    "    \n",
    "    weights = [v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4]\n",
    "    \n",
    "    weights_df = pd.DataFrame(data = {\"E/Loss function\": E(alp,*weights), \n",
    "                                  \"weights\": [weights]})\n",
    "    \n",
    "    for i in range(nr_iterations):\n",
    "        weights, new_E, old_E = update_weights(alp,learn_rate,*weights)\n",
    "        \n",
    "        new_weights_df = pd.DataFrame(data = {\"E/Loss function\": new_E, \n",
    "                                  \"weights\": [weights]})\n",
    "        \n",
    "        weights_df = weights_df.append(new_weights_df)\n",
    "    \n",
    "    weights_df.index = list(range(0,nr_iterations+1))\n",
    "    weights_df.index = weights_df.index.rename(\"iteration\")\n",
    "    \n",
    "    return weights_df\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THE FOLLOWING. GIVES THE BEST RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-299a04ab644b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 123 approximates pretty well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 131 seed also approximates well. Learn_rate 0.02 and nr iterations 2500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m131\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msampl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "learn_rate = 0.02\n",
    "nr_iterations = 2500\n",
    "alp = 0.64\n",
    "\n",
    "# 123 approximates pretty well\n",
    "# 131 seed also approximates well. Learn_rate 0.02 and nr iterations 2500\n",
    "np.random.seed(131)\n",
    "sampl = np.random.uniform(low=-2, high=5, size=(15,))\n",
    "v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4 = sampl\n",
    "\n",
    "\n",
    "# final_df = iterate_updation_of_weights(nr_iterations,alp,learn_rate,v0,v1,v2,v3,v4,w0,w1,w2,w3,w4,u0,u1,u2,u3,u4)\n",
    "# final_df.to_csv('results_from_tests/best_results_example1_paper_alpha05.csv')\n",
    "final_df = pd.read_csv('results_from_tests/best_results_example1_paper_alpha05.csv')\n",
    "\n",
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-3.2500425074739066, 0.06517764929896742, -2.456870562726377, -0.8857496494748025, 1.0374173439365972, -4.285306660360693, -12.748119921500095, -0.9823376868048198, -5.452885363756848, 3.920820543709355, -3.4549412752160857, -8.75876944658546, -0.7446350973460544, -6.8020451112389315, 2.827700193317643]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weights = final_df.weights.iloc[-1]\n",
    "final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.2500425074739066,\n",
       " 0.06517764929896742,\n",
       " -2.456870562726377,\n",
       " -0.8857496494748025,\n",
       " 1.0374173439365972,\n",
       " -4.285306660360693,\n",
       " -12.748119921500095,\n",
       " -0.9823376868048198,\n",
       " -5.452885363756848,\n",
       " 3.920820543709355,\n",
       " -3.4549412752160857,\n",
       " -8.75876944658546,\n",
       " -0.7446350973460544,\n",
       " -6.8020451112389315,\n",
       " 2.827700193317643]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weights = final_df.weights.iloc[-1]\n",
    "final_weights = final_weights.replace('[','').replace(']','').split(',')\n",
    "final_weights = [float(x) for x in final_weights]\n",
    "final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E/Loss function</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iteration</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002070</td>\n",
       "      <td>[-3.249505783726952, 0.06517730944141648, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002067</td>\n",
       "      <td>[-3.249488122092342, 0.06517729817391775, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002064</td>\n",
       "      <td>[-3.2494704750292933, 0.06517728691030297, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002061</td>\n",
       "      <td>[-3.249452842518182, 0.0651772756505669, -2.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002058</td>\n",
       "      <td>[-3.2494352245394222, 0.06517726439470427, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002055</td>\n",
       "      <td>[-3.249417621073466, 0.06517725314270985, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002052</td>\n",
       "      <td>[-3.249400032100805, 0.0651772418945784, -2.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002049</td>\n",
       "      <td>[-3.2493824576019676, 0.06517723065030469, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002046</td>\n",
       "      <td>[-3.2493648975575202, 0.06517721940988352, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002043</td>\n",
       "      <td>[-3.2493473519480682, 0.06517720817330971, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002040</td>\n",
       "      <td>[-3.249329820754254, 0.06517719694057805, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002037</td>\n",
       "      <td>[-3.2493123039567577, 0.06517718571168338, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002034</td>\n",
       "      <td>[-3.2492948015362977, 0.06517717448662051, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002031</td>\n",
       "      <td>[-3.2492773134736295, 0.0651771632653843, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002029</td>\n",
       "      <td>[-3.249259839749546, 0.06517715204796957, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002026</td>\n",
       "      <td>[-3.249242380344877, 0.06517714083437123, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002023</td>\n",
       "      <td>[-3.249224935240491, 0.06517712962458413, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002020</td>\n",
       "      <td>[-3.2492075044172926, 0.06517711841860317, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002017</td>\n",
       "      <td>[-3.2491900878562237, 0.06517710721642322, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002014</td>\n",
       "      <td>[-3.249172685538263, 0.06517709601803921, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002011</td>\n",
       "      <td>[-3.249155297444427, 0.06517708482344604, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002009</td>\n",
       "      <td>[-3.2491379235557676, 0.06517707363263865, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002006</td>\n",
       "      <td>[-3.249120563853375, 0.06517706244561197, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002003</td>\n",
       "      <td>[-3.2491032183183752, 0.06517705126236095, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>[-3.2490858869319306, 0.06517704008288054, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001997</td>\n",
       "      <td>[-3.2490685696752406, 0.06517702890716572, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001994</td>\n",
       "      <td>[-3.2490512665295403, 0.06517701773521145, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001992</td>\n",
       "      <td>[-3.249033977476102, 0.06517700656701272, -2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001989</td>\n",
       "      <td>[-3.2490167024962338, 0.06517699540256455, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001986</td>\n",
       "      <td>[-3.2489994415712795, 0.06517698424186193, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001983</td>\n",
       "      <td>[-3.2489821946826196, 0.06517697308489988, -2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           E/Loss function                                            weights\n",
       "iteration                                                                    \n",
       "0                 0.002070  [-3.249505783726952, 0.06517730944141648, -2.4...\n",
       "1                 0.002067  [-3.249488122092342, 0.06517729817391775, -2.4...\n",
       "2                 0.002064  [-3.2494704750292933, 0.06517728691030297, -2....\n",
       "3                 0.002061  [-3.249452842518182, 0.0651772756505669, -2.45...\n",
       "4                 0.002058  [-3.2494352245394222, 0.06517726439470427, -2....\n",
       "5                 0.002055  [-3.249417621073466, 0.06517725314270985, -2.4...\n",
       "6                 0.002052  [-3.249400032100805, 0.0651772418945784, -2.45...\n",
       "7                 0.002049  [-3.2493824576019676, 0.06517723065030469, -2....\n",
       "8                 0.002046  [-3.2493648975575202, 0.06517721940988352, -2....\n",
       "9                 0.002043  [-3.2493473519480682, 0.06517720817330971, -2....\n",
       "10                0.002040  [-3.249329820754254, 0.06517719694057805, -2.4...\n",
       "11                0.002037  [-3.2493123039567577, 0.06517718571168338, -2....\n",
       "12                0.002034  [-3.2492948015362977, 0.06517717448662051, -2....\n",
       "13                0.002031  [-3.2492773134736295, 0.0651771632653843, -2.4...\n",
       "14                0.002029  [-3.249259839749546, 0.06517715204796957, -2.4...\n",
       "15                0.002026  [-3.249242380344877, 0.06517714083437123, -2.4...\n",
       "16                0.002023  [-3.249224935240491, 0.06517712962458413, -2.4...\n",
       "17                0.002020  [-3.2492075044172926, 0.06517711841860317, -2....\n",
       "18                0.002017  [-3.2491900878562237, 0.06517710721642322, -2....\n",
       "19                0.002014  [-3.249172685538263, 0.06517709601803921, -2.4...\n",
       "20                0.002011  [-3.249155297444427, 0.06517708482344604, -2.4...\n",
       "21                0.002009  [-3.2491379235557676, 0.06517707363263865, -2....\n",
       "22                0.002006  [-3.249120563853375, 0.06517706244561197, -2.4...\n",
       "23                0.002003  [-3.2491032183183752, 0.06517705126236095, -2....\n",
       "24                0.002000  [-3.2490858869319306, 0.06517704008288054, -2....\n",
       "25                0.001997  [-3.2490685696752406, 0.06517702890716572, -2....\n",
       "26                0.001994  [-3.2490512665295403, 0.06517701773521145, -2....\n",
       "27                0.001992  [-3.249033977476102, 0.06517700656701272, -2.4...\n",
       "28                0.001989  [-3.2490167024962338, 0.06517699540256455, -2....\n",
       "29                0.001986  [-3.2489994415712795, 0.06517698424186193, -2....\n",
       "30                0.001983  [-3.2489821946826196, 0.06517697308489988, -2...."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate again\n",
    "learn_rate = 0.02\n",
    "final_df = iterate_updation_of_weights(30,alp,learn_rate,*final_weights)\n",
    "final_weights = final_df.weights.iloc[-1]\n",
    "final_df.to_csv('results_from_tests/best_results_example1_paper_alpha05.csv')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.2489821946826196,\n",
       " 0.06517697308489988,\n",
       " -2.4579038836339446,\n",
       " -0.8857218260473451,\n",
       " 1.0432864849222523,\n",
       " -4.2859273125337785,\n",
       " -12.748119912114529,\n",
       " -0.9715596788071368,\n",
       " -5.452893225269985,\n",
       " 3.921073537347592,\n",
       " -3.4583691993701153,\n",
       " -8.75876949065217,\n",
       " -0.7379962283055045,\n",
       " -6.8020697573777404,\n",
       " 2.829837668911569]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing The results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0,1,10)\n",
    "y = [i*compute_neural_network(i,*final_weights) for i in x]\n",
    "plt.plot(x,y)\n",
    "\n",
    "x_a = [n*0.1 for n in range(0,10)]\n",
    "y_a = [2/3*i**(3/2) for i in x_a]\n",
    "plt.plot(x_a,y_a)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested it and the results are consistent: i.e., if I use different weights and find the Error, the output\n",
    "function is always the same. \n",
    "The problem is that the results are not the same as in the paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analytical solution is $$2/3x^{3/2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.024691358024691357,\n",
       " 0.06983770678385653,\n",
       " 0.12830005981991682,\n",
       " 0.19753086419753085,\n",
       " 0.276057774999974,\n",
       " 0.36288736930121157,\n",
       " 0.4572903500605464,\n",
       " 0.5587016542708523,\n",
       " 0.6666666666666666]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
